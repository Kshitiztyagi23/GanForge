{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yWGWpwls76_T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    annotations = []\n",
        "    for obj in root.findall('object'):\n",
        "        filename = root.find('filename').text\n",
        "        label = obj.find('name').text\n",
        "        bbox = obj.find('bndbox')\n",
        "        coords = {\n",
        "            'xmin': int(bbox.find('xmin').text),\n",
        "            'ymin': int(bbox.find('ymin').text),\n",
        "            'xmax': int(bbox.find('xmax').text),\n",
        "            'ymax': int(bbox.find('ymax').text)\n",
        "        }\n",
        "        annotations.append({'filename': filename, 'label': label, 'bbox': coords})\n",
        "    return annotations\n",
        "ANNOTATION_PATH = '/kaggle/input/face-mask-detection/annotations'\n",
        "xml_files = [os.path.join(ANNOTATION_PATH, filename) for filename in os.listdir(ANNOTATION_PATH)]\n",
        "\n",
        "data = []\n",
        "for xml_file in xml_files:\n",
        "    annotations = parse_xml(xml_file)\n",
        "\n",
        "    for annotation in annotations:\n",
        "        data.append([annotation['filename'], annotation['label'], annotation['bbox']])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['filename', 'label', 'bbox'])\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "PZCo3_0B9LVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_annotation(image_path, annotations):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    for ann in annotations:\n",
        "        bbox = ann['bbox']\n",
        "        cv2.rectangle(image, (bbox['xmin'], bbox['ymin']), (bbox['xmax'], bbox['ymax']), (255, 0, 0), 2)\n",
        "        cv2.putText(image, ann['label'], (bbox['xmin'], bbox['ymin'] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "visualize_annotation('/kaggle/input/face-mask-detection/images/maksssksksss0.png', parse_xml('/kaggle/input/face-mask-detection/annotations/maksssksksss0.xml'))"
      ],
      "metadata": {
        "id": "PwPpoJPS8AZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = '/kaggle/input/face-mask-detection/images/'\n",
        "label_pair = {\n",
        "    'with_mask': 0,\n",
        "    'without_mask': 1,\n",
        "    'mask_weared_incorrect': 2\n",
        "}\n",
        "\n",
        "face_images = []\n",
        "face_labels = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    row = df.iloc[i]\n",
        "    bbox = row['bbox']\n",
        "    image = cv2.imread(IMAGE_PATH + row['filename'])\n",
        "    image = image[bbox['ymin']:bbox['ymax'], bbox['xmin']:bbox['xmax']]\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    face_images.append(image)\n",
        "    face_labels.append(label_pair[row['label']])\n",
        "\n",
        "face_images = np.array(face_images, dtype='float32')\n",
        "face_labels = np.array(face_labels)"
      ],
      "metadata": {
        "id": "S1qCpJqI8PIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = ImageDataGenerator(\n",
        "    zoom_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 25,\n",
        "    fill_mode = 'nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "I0a0GOxX8RSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(face_images, face_labels, test_size=0.2, shuffle=42, stratify=face_labels)"
      ],
      "metadata": {
        "id": "snPRnAqe8TUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = tf.keras.layers.Flatten()(base_model.output)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=x)\n"
      ],
      "metadata": {
        "id": "SDSd1MyS8Wai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "history = model.fit(\n",
        "    augmentation.flow(train_x, train_y, batch_size=16),\n",
        "    validation_data = (test_x, test_y),\n",
        "    epochs = 20\n",
        ")"
      ],
      "metadata": {
        "id": "5v5St3uK8XLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mask_detection.h5')\n",
        "plt.figure()\n",
        "plt.title('Train and Validation Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3cVHnKoA8Z2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "!wget https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "metadata": {
        "id": "czjKE61r8j8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/kaggle/working/deploy.prototxt\"  # Replace with your prototxt path\n",
        "weights_path = \"/kaggle/working/res10_300x300_ssd_iter_140000.caffemodel\"  # Replace with your caffemodel path\n",
        "face_net = cv2.dnn.readNetFromCaffe(model_path, weights_path)\n",
        "label_pair_reversed = {\n",
        "    0: 'with_mask',\n",
        "    1: 'without_mask',\n",
        "    2: 'mask_weared_incorrect'\n",
        "}\n",
        "def predict_image(filepath):\n",
        "    image = cv2.imread(filepath)\n",
        "    (h, w) = image.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=(104.0, 177.0, 123.0))\n",
        "    face_net.setInput(blob)\n",
        "    detections = face_net.forward()\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > 0.2:\n",
        "            box = detections[0, 0, i, 3:7] * [w, h, w, h]\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "            face = image[startY:endY, startX:endX]\n",
        "            face = cv2.resize(face, (224, 224))\n",
        "            face = img_to_array(face)\n",
        "            face = tf.expand_dims(face, axis=0)\n",
        "            face = preprocess_input(face)\n",
        "            label = model.predict(face)\n",
        "            label = np.argmax(label, axis=1)[0]\n",
        "            cv2.putText(image, label_pair_reversed[label], (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "predict_image('/kaggle/input/face-mask-detection/images/maksssksksss129.png')"
      ],
      "metadata": {
        "id": "TvtV4-zP8kYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}